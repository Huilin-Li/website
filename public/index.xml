<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Introduction on Huilin Li</title>
    <link>http://localhost:1313/</link>
    <description>Recent content in Introduction on Huilin Li</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>The periodic table, electron shells, and orbitals</title>
      <link>http://localhost:1313/posts/blog/one/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/blog/one/</guid>
      <description>Differences in chemical reactivity between elements are based on the number and spatial distribution of their electrons.&#xA;The Bohr model shows the atom as a central nucleus containing protons and neutrons, with the electrons in circular electron shells at specific distances from the nucleus, similar to planets orbiting around the sun. Each electron shell has a different energy level, with those shells closest to the nucleus being lower in energy than those farther from the nucleus.</description>
    </item>
    <item>
      <title>truncation</title>
      <link>http://localhost:1313/docs/project/binderdesign/truncation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/project/binderdesign/truncation/</guid>
      <description>target.pdb preprocessing&#xD;#&#xD;Assuming we have a target protein target.pdb, and we want to create a binder to target.pdb. The first step is preprocessing target.pdb. Generally spearking, there are two steps we need to think of.&#xA;Truncating target.pdb&#xD;#&#xD;Truncating target protein helps a lot in reducing the stress of computing. For example, we could remove AAs with very low pLDDT or AAs who are far away from the place we want binders to bind with.</description>
    </item>
    <item>
      <title>design binders via RFdiffusion and ProteinMPNN-FastRelax</title>
      <link>http://localhost:1313/docs/project/binderdesign/design/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/project/binderdesign/design/</guid>
      <description>In my use case, firstly, I tried to de novo design binders. However, I found that designed binders are limited to proteins with only one helix. Then, I changed to design binders based on scaffolds. The design process and scripts I used a lot are as follows.&#xA;Three needed designing environments&#xD;#&#xD;Thanks a lot to the great work, RFdiffusion and ProteinMPNN-FastRelax, as well as AlphaFold2, who give us great ways to design proteins.</description>
    </item>
    <item>
      <title>PyMol commands</title>
      <link>http://localhost:1313/posts/blog/pymol/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/blog/pymol/</guid>
      <description> select residues based on residue number select nterm, resi 42+74+43+56+39 mutate one amino acid cmd.wizard(&amp;#34;mutagenesis&amp;#34;) cmd.fetch(&amp;#34;target.pdb&amp;#34;) cmd.get_wizard().set_mode(&amp;#34;LEU&amp;#34;) cmd.get_wizard().do_select(&amp;#34;chain A and resid 22&amp;#34;) cmd.get_wizard().apply() cmd.save(&amp;#34;mutated_target.pdb&amp;#34;) </description>
    </item>
    <item>
      <title>Helpul python/pandas scripts</title>
      <link>http://localhost:1313/posts/blog/python/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/blog/python/</guid>
      <description>So&amp;hellip;, I find I used these codes a lot, and they are very helpful for effectivity.&#xA;Assign files into different folders&#xD;#&#xD;Assuming I have 230 files in db_folder, and I want to copy these 230 files into different folders (folder0, folder1 and so on) with at least 50 files in each folder.&#xA;files_list contains names of these 230 files, like files_list=[&amp;quot;file1&amp;quot;, &amp;quot;file2&amp;quot;, ..., &amp;quot;file230&amp;quot;]&#xA;import shutil chunks = [files_list[x:x+50] for x in range(0, len(files_list), 50)] # len(chunks) = 5 for i in range(53): chunk = chunks[i] newpath = &amp;#34;db_folder/folder&amp;#34; + str(i) if not os.</description>
    </item>
    <item>
      <title>pae_interaction score</title>
      <link>http://localhost:1313/docs/project/binderdesign/pae_score/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/project/binderdesign/pae_score/</guid>
      <description>As RFdiffusion states, we expect a binder whose pae_interaction score is lower than 10. However, we should also have a look at other scores, such as pLDDT, rmsd.&#xA;check_n = 6 folder_nam = [&amp;#34;folder&amp;#34;+str(i) for i in range(check_n)] score_paths = [&amp;#34;../MyBinderWork/ThreeThoudand_mpnn_af/&amp;#34;+nam+&amp;#34;/score.sc&amp;#34; for nam in folder_nam] ALL_DF = [] for p in score_paths: df = pd.read_csv(p, delim_whitespace=True) ALL_DF.append(df) SCORE_df = pd.concat(ALL_DF)[[&amp;#34;binder_aligned_rmsd&amp;#34;, &amp;#34;pae_binder&amp;#34;, &amp;#34;pae_interaction&amp;#34;, &amp;#34;plddt_binder&amp;#34;, &amp;#34;description&amp;#34;]] An example of one of my experiments&#xD;</description>
    </item>
    <item>
      <title>backbones filtering</title>
      <link>http://localhost:1313/docs/project/binderdesign/filtering/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/project/binderdesign/filtering/</guid>
      <description>In design binders via RFdiffusion and ProteinMPNN-FastRelax, at the beginning of sequence design and binder assessment script mpnn_af.slm, we could perform a fitering step to remove useless backnones.&#xA;In my opinion, this is a very heloful step, because it greatly increase the speed and efficiency of desigining reasonable binders. For example, in my target.pdb, I only expect designed binders could bind with the outside part of the target.pdb (see fig.1).</description>
    </item>
    <item>
      <title>notes</title>
      <link>http://localhost:1313/docs/project/binderdesign/notes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/project/binderdesign/notes/</guid>
      <description> RFdiffusion is better at designing binders for target proteins that are already existing or have been verified by experiments. If the target protein is predcited by AI models, and has not been verified by experiments, the probability of designing a potential binder for this target will be reduced. The number of designed binders should be huge, in order to pick potential candidates as many as possible. </description>
    </item>
    <item>
      <title>4 levels of protein structure</title>
      <link>http://localhost:1313/posts/blog/proteinstruture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/blog/proteinstruture/</guid>
      <description>There are four levels of protein structure: primary, secondary, tertiary and quaternary.&#xA;Primary Structure.&#xD;#&#xD;A protein’s primary structure is the unique sequence of amino acids in each polypeptide chain that makes up the protein.&#xA;fasta file sequence of 20 amino acids Secondary Structure&#xD;#&#xD;Reference:&#xD;#&#xD;3.9: Proteins - Protein Structure </description>
    </item>
    <item>
      <title>A simple Bayesian inference example with Grid approximate, from scratch</title>
      <link>http://localhost:1313/posts/ml/bayes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/ml/bayes/</guid>
      <description>why Bayesian?&#xD;#&#xD;Using probability methods to solve statistical problems.&#xA;For many problems in real life, we normally have an educated guess (prior), and this prior is helpful to our final guess/prediction. Through observing new data/evidence, we are upating our guess(prior), and the updated guess is posterior.&#xA;In the Bayesian inference workflow, we treat problems interatively, that is, we can get a new posterior through new observations, and then use it as the (new) prior.</description>
    </item>
    <item>
      <title>All about Latex and Overleaf</title>
      <link>http://localhost:1313/posts/blog/overleaf/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/blog/overleaf/</guid>
      <description>\documentclass{article}&#xD;\usepackage[utf8]{inputenc}&#xD;\usepackage{tcolorbox}&#xD;\newtcbox{\inlinecode}{on line, boxrule=0pt, boxsep=0pt, top=2pt, left=2pt, bottom=2pt, right=2pt, colback=gray!15, colframe=white, fontupper={\ttfamily \footnotesize}}&#xD;\begin{document}&#xD;This is a sample of some inline code: \inlinecode{int x = 0;}.&#xD;\end{document} Remove the space on the left hand of the beginning of a paragraph \noindent Typeseeting programming packages/libraries in LaTex \textsc{} </description>
    </item>
    <item>
      <title>Bash Scripts</title>
      <link>http://localhost:1313/posts/blog/shell/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/blog/shell/</guid>
      <description>Bash Scripts&#xD;#&#xD;How to discard changes in VScode?&#xD;#&#xD;Navigate to reporsitory (has .github folder) with changes. Then, git restore &amp;lt;file&amp;gt; Activate conda environment in bash script&#xD;#&#xD;source ~/miniconda3/etc/profile.d/conda.sh conda activate ENV SBATCH Array jobs&#xD;#&#xD;#SBATCH -J array-job&#x9;#SBATCH -a 1-3 #SBATCH -o array-job.%A.%a.log id_list=&amp;#34;./id_list.txt&amp;#34; id=`head -n $SLURM_ARRAY_TASK_ID $id_list | tail -n 1` python3 script.py -in $id srun gpu&#xD;#&#xD;srun -N 1 --ntasks-per-node 2 -p v100 -q gpu --gres=gpu:1 --mem=50G --pty /bin/bash run scripts&#xD;#&#xD;sbatch test.</description>
    </item>
    <item>
      <title>Biomacromolecules: Protein and ligand</title>
      <link>http://localhost:1313/posts/proteomics/biomacromolecules/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/proteomics/biomacromolecules/</guid>
      <description>protein&#xD;#&#xD;Proteins are polymers(聚合物). They,macromolecules, are made up of many smaller molectules. These small molecules that made up proteins are amino acides. carbon atom, next to the carboxyl group(羧基) is called the α–carbon. It bears the amine group(氨基) and the R group(side chain), as well as a hydrogen atom. Amine group(氨基). Carboxyl group(羧基). Side chain(R group), only variable part. reference:&#xA;[1] https://en.wikipedia.org/wiki/Amino_acid&#xA;[2] https://blog.csdn.net/qq_52466006/article/details/143084356</description>
    </item>
    <item>
      <title>commonly used python codes</title>
      <link>http://localhost:1313/posts/proteomics/pythonblocks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/proteomics/pythonblocks/</guid>
      <description>&#xD;unzip compressed files into a new directory&#xD;#&#xD;gz_file = os.path.join(root, file) out_file = &amp;#34;new_path/&amp;#34; + file with gzip.open(gz_file,&amp;#34;rb&amp;#34;) as f_in, open(out_file,&amp;#34;wb&amp;#34;) as f_out: shutil.copyfileobj(f_in, f_out) copy and move&#xD;#&#xD;import shutil shutil.copyfile(&amp;#34;old_path/file.txt&amp;#34;, &amp;#34;new_path/file.txt&amp;#34;) </description>
    </item>
    <item>
      <title>commonly used Shell script and Command line, when working on large dataset in HPC</title>
      <link>http://localhost:1313/posts/proteomics/command/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/proteomics/command/</guid>
      <description>ls -l | wc -l wget -i links.txt -o wget.log tar -tzf file.tar.gz | wc -l # count files in tar.gz without unzip # it actually counts lines, and it will cause counting \n as a line tar -zcvf myfolder.tar.gz myfolder cp ./folder/*.txt ./newfolder gunzip *.gz # for f in *.gz; do gunzip &amp;#34;$f&amp;#34;; done cat *.fa &amp;gt; all_data.fa # concatenate multiple fasta files into one fasta file in command line source ~/miniconda3/etc/profile.</description>
    </item>
    <item>
      <title>databases: PDB, Swiss-Prot, OMG_Prot50</title>
      <link>http://localhost:1313/posts/proteomics/database/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/proteomics/database/</guid>
      <description>PDB database Swiss-Prot database (AI-predicted structures) OMG_Prot50 (Proteins are transcribed from the Open MetaGenomic.) PDB database&#xD;#&#xD;download&#xD;#&#xD;https://files.rcsb.org/pub/pdb/data/structures/all/pdb/ save this website as PDB - FTP Archive over HTTP.html extract pdbXXXX.ent.gz list from bs4 import BeautifulSoup # how many ent.gz file with open(&amp;#39;PDB - FTP Archive over HTTP.html&amp;#39;, &amp;#39;r&amp;#39;) as file: html_content = file.read() soup = BeautifulSoup(html_content, &amp;#39;lxml&amp;#39;) text = soup.get_text(&amp;#39;\n&amp;#39;, &amp;#39;\n\n&amp;#39;) lines = text.split(&amp;#39;\n&amp;#39;) PDB_id_list = [] for line in lines: if &amp;#39;ent.</description>
    </item>
    <item>
      <title>Encoding Protein Sequences into Integer Representations Using K-mer Binary Mapping</title>
      <link>http://localhost:1313/posts/proteomics/kmerbinarymap/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/proteomics/kmerbinarymap/</guid>
      <description>seq=&amp;quot;MKTLGEFIVEKQH&amp;quot;, k=4.&#xA;Kmers: [&#39;MKTL&#39;, &#39;KTLG&#39;, &#39;TLGE&#39;, &#39;LGEF&#39;, &#39;GEFI&#39;, &#39;EFIV&#39;, &#39;FIVE&#39;, &#39;IVEK&#39;, &#39;VEKQ&#39;, &#39;EKQH&#39;]&#xA;Encodings: [5057, 15385, 49556, 6470, 37986, 17954, 25124, 8771, 9268, 17226]&#xA;Check:&#xA;Kmer K-mer Binary Mapping Encoding Check &amp;ldquo;MKTL&amp;rdquo; 0001 0011 1100 0001 5057 ✔️ &amp;ldquo;KTLG&amp;rdquo; 0011 1100 0001 1001 15385 ✔️ &amp;ldquo;TLGE&amp;rdquo; 1100 0001 1001 0100 49556 ✔️ &amp;ldquo;LGEF&amp;rdquo; 0001 1001 0100 0110 6470 ✔️ &amp;ldquo;GEFI&amp;rdquo; 1001 0100 0110 0010 37986 ✔️ &amp;ldquo;EFIV&amp;rdquo; 0100 0110 0010 0010 17954 ✔️ &amp;ldquo;FIVE&amp;rdquo; 0110 0010 0010 0100 25124 ✔️ &amp;ldquo;IVEK&amp;rdquo; 0010 0010 0100 0011 8771 ✔️ &amp;ldquo;VEKQ&amp;rdquo; 0010 0100 0011 0100 9268 ✔️ &amp;ldquo;EKQH&amp;rdquo; 0100 0011 0100 1010 17226 ✔️ Code:</description>
    </item>
    <item>
      <title>Excel commands</title>
      <link>http://localhost:1313/posts/blog/excel/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/blog/excel/</guid>
      <description> In one row, concat each cell into one cell as string =CONCAT(A1:D1) </description>
    </item>
    <item>
      <title>fasta 2 mutated fasta (python code)</title>
      <link>http://localhost:1313/posts/proteomics/fa2mutatedfa/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/proteomics/fa2mutatedfa/</guid>
      <description>import copy mutations = [&amp;#34;K114Q&amp;#34;, &amp;#34;R196I&amp;#34;, &amp;#34;Y20F&amp;#34;, &amp;#34;K8Q&amp;#34;] fa_header = open(&amp;#34;./xxxx.fasta&amp;#34;, &amp;#34;r&amp;#34;).read().split(&amp;#34;\n&amp;#34;)[0] fa_seq = open(&amp;#34;./xxxx.fasta&amp;#34;, &amp;#34;r&amp;#34;).read().split(&amp;#34;\n&amp;#34;)[1] new_seq = copy.copy(fa_seq) for mutation in mutations: orig = mutation[0] idx = int(mutation[1:-1]) mut = mutation[-1] seq_list = list(new_seq) if seq_list[idx-1] == orig: seq_list[idx-1] = mut else: print(&amp;#34;Check!&amp;#34;) new_seq = &amp;#39;&amp;#39;.join(seq_list) with open(&amp;#39;mutatedfa.fa&amp;#39;, &amp;#39;w&amp;#39;) as f: f.write(fa_header) f.write(&amp;#34;\n&amp;#34;) f.write(new_seq) </description>
    </item>
    <item>
      <title>fasta similarity</title>
      <link>http://localhost:1313/posts/proteomics/fasimilarity/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/proteomics/fasimilarity/</guid>
      <description>&#xD;import parasail&#xD;#&#xD;result = parasail.sw_trace_scan_16(&amp;#34;asdf&amp;#34;, &amp;#34;asdf&amp;#34;, 11, 1, parasail.blosum62) </description>
    </item>
    <item>
      <title>files list</title>
      <link>http://localhost:1313/posts/proteomics/files/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/proteomics/files/</guid>
      <description>&#xD;list files in a folder&#xD;#&#xD;import glob files = glob.glob(&amp;#39;CSV/*.csv&amp;#39;) # [&amp;#39;CSV\\x_109.csv&amp;#39;, &amp;#39;CSV\\x_116.csv&amp;#39;, &amp;#39;CSV\\x_121.csv&amp;#39;, ... ] #&#xD;</description>
    </item>
    <item>
      <title>foldseek usage (straightforward)</title>
      <link>http://localhost:1313/posts/proteomics/foldseek/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/proteomics/foldseek/</guid>
      <description>foldseek github Foldseek User Guide Installation: Conda installer (Linux and macOS)&#xD;#&#xD;conda install -c conda-forge -c bioconda foldseek Customize Database&#xD;#&#xD;folsseek createdb myDB_dir/ myDB&#xD;# myDB_dir has lots of pdb files foldseek easy-search&#xD;#&#xD;usage: foldseek easy-search &amp;lt;i:PDB|mmCIF[.gz]&amp;gt; ... &amp;lt;i:PDB|mmCIF[.gz]&amp;gt;|&amp;lt;i:stdin&amp;gt; &amp;lt;i:targetFastaFile[.gz]&amp;gt;|&amp;lt;i:targetDB&amp;gt; &amp;lt;o:alignmentFile&amp;gt; &amp;lt;tmpDir&amp;gt; [options]&#xD;By Martin Steinegger &amp;lt;martin.steinegger@snu.ac.kr&amp;gt;&#xD;options: prefilter:&#xD;--comp-bias-corr INT Correct for locally biased amino acid composition (range 0-1) [1]&#xD;--comp-bias-corr-scale FLOAT Correct for locally biased amino acid composition (range 0-1) [1.</description>
    </item>
    <item>
      <title>Hugo commands</title>
      <link>http://localhost:1313/posts/blog/hugo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/blog/hugo/</guid>
      <description>Some commands and issues you might want to know when building the website using Hugo, including inserting images and resize and center images,adding emoji, travel map, linking to pages and titles, and so on.&#xA;SUMMARY&#xD;#&#xD;use themes as your own repositories insert and resize images center images add emoji add travel map Why my local website doesn&amp;rsquo;t update after I update my markdown files? link pages and tiles Add Giscus comment in Hugo-book theme Remove git in themes, and use themes as your own repositories.</description>
    </item>
    <item>
      <title>K-means, Gaussian mixture model, Fuzzy clustering, Spectral Clustering cluster protein based on distance</title>
      <link>http://localhost:1313/posts/proteomics/clustering/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/proteomics/clustering/</guid>
      <description>&#xD;Spectral Clustering&#xD;#&#xD;</description>
    </item>
    <item>
      <title>KD value: binding affinity data</title>
      <link>http://localhost:1313/posts/proteomics/kd/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/proteomics/kd/</guid>
      <description>\(K_{D}\):the equilibrium dissociation constant. \(K_{D}\) and affinity are inversely related. \[&#xD;K_{D}=\frac{k_{off}}{k_{on}} \] \(K_{D}\) value relates to the concentration of ligand (the amount of ligand needed for a particular experiment) and so the lower \(K_{D}\) value (lower concentration) and thus the higher the affinity of the ligand.</description>
    </item>
    <item>
      <title>parasail in C usage (straightforward)</title>
      <link>http://localhost:1313/posts/proteomics/parasailc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/proteomics/parasailc/</guid>
      <description>I want to use its Tracebacks functions, however, this function has not been involved in Python version. Therefore, I am exploring its C usage.&#xA;installation (&amp;ldquo;building from a git clone&amp;rdquo;)&#xD;#&#xD;Installation instructions on the parasail Github&#xD;straightforward steps:&#xA;cd /storage/lihuilin/ git clone https://github.com/jeffdaily/parasail cd parasail autoreconf -fi output&#xD;libtoolize: putting auxiliary files in AC_CONFIG_AUX_DIR, &amp;#39;build-aux&amp;#39;.&#xD;libtoolize: copying file &amp;#39;build-aux/ltmain.sh&amp;#39;&#xD;libtoolize: putting macros in AC_CONFIG_MACRO_DIRS, &amp;#39;m4&amp;#39;.&#xD;libtoolize: copying file &amp;#39;m4/libtool.m4&amp;#39;&#xD;libtoolize: copying file &amp;#39;m4/ltoptions.</description>
    </item>
    <item>
      <title>pdb 2 fasta</title>
      <link>http://localhost:1313/posts/proteomics/pdb2fasta/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/proteomics/pdb2fasta/</guid>
      <description>from Bio import SeqIO def pdb2fasta(pdb_file, fasta_file, HEADER=None): with open(pdb_file, &amp;#39;r&amp;#39;) as pdb_file: for record in SeqIO.parse(pdb_file, &amp;#39;pdb-atom&amp;#39;): if &amp;#39;?&amp;#39; in record.id: header = HEADER else: header = record.id with open(fasta_file, &amp;#39;w&amp;#39;) as fasta_file: fasta_file.write(&amp;#39;&amp;gt;&amp;#39; + header+&amp;#39;\n&amp;#39;) fasta_file.write(str(record.seq)) return record.seq </description>
    </item>
    <item>
      <title>pdb 2 pdbs of chains</title>
      <link>http://localhost:1313/posts/proteomics/pdb2chains/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/proteomics/pdb2chains/</guid>
      <description>from Bio import PDB if __name__==&amp;#34;__main__&amp;#34;: for pdbfile_path in glob.glob(&amp;#34;/path/DB/pure_PDB/*.pdb&amp;#34;): name = pdbfile_path.split(&amp;#34;\\&amp;#34;)[-1].split(&amp;#34;.&amp;#34;)[0] print(name, end=&amp;#34; &amp;#34;) pdb = PDB.PDBParser().get_structure(name, pdbfile_path) pdb_io = PDB.PDBIO() pdb_chains = pdb.get_chains() for chain in pdb_chains: pdb_io.set_structure(chain) pdb_io.save(&amp;#34;/path/DB/pure_PDB_DB_by_Chain/&amp;#34; + pdb.get_id() + &amp;#34;_&amp;#34; + chain.get_id() + &amp;#34;.pdb&amp;#34;) print(&amp;#39;-- Done&amp;#39;) </description>
    </item>
    <item>
      <title>Plotly: Copy&amp;Paste Continuous and Discrete colors</title>
      <link>http://localhost:1313/posts/blog/plotlycolor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/blog/plotlycolor/</guid>
      <description>Discrete color names&#xD;#&#xD;aliceblue&#xD;antiquewhite&#xD;aqua&#xD;aquamarine&#xD;azure&#xD;beige&#xD;bisque&#xD;black&#xD;blanchedalmond&#xD;blue&#xD;blueviolet&#xD;brown&#xD;burlywood&#xD;cadetblue&#xD;chartreuse&#xD;chocolate&#xD;coral&#xD;cornflowerblue&#xD;cornsilk&#xD;crimson&#xD;cyan&#xD;darkblue&#xD;darkcyan&#xD;darkgoldenrod&#xD;darkgray&#xD;darkgrey&#xD;darkgreen&#xD;darkkhaki&#xD;darkmagenta&#xD;darkolivegreen&#xD;darkorange&#xD;darkorchid&#xD;darkred&#xD;darksalmon&#xD;darkseagreen&#xD;darkslateblue&#xD;darkslategray&#xD;darkslategrey&#xD;darkturquoise&#xD;darkviolet&#xD;deeppink&#xD;deepskyblue&#xD;dimgray&#xD;dimgrey&#xD;dodgerblue&#xD;firebrick&#xD;floralwhite&#xD;forestgreen&#xD;fuchsia&#xD;gainsboro&#xD;ghostwhite&#xD;gold&#xD;goldenrod&#xD;gray&#xD;grey&#xD;green&#xD;greenyellow&#xD;honeydew&#xD;hotpink&#xD;indianred&#xD;indigo&#xD;ivory&#xD;khaki&#xD;lavender&#xD;lavenderblush&#xD;lawngreen&#xD;lemonchiffon&#xD;lightblue&#xD;lightcoral&#xD;lightcyan&#xD;lightgoldenrodyellow&#xD;lightgray&#xD;lightgrey&#xD;lightgreen&#xD;lightpink&#xD;lightsalmon&#xD;lightseagreen&#xD;lightskyblue&#xD;lightslategray&#xD;lightslategrey&#xD;lightsteelblue&#xD;lightyellow&#xD;lime&#xD;limegreen&#xD;linen&#xD;magenta&#xD;maroon&#xD;mediumaquamarine&#xD;mediumblue&#xD;mediumorchid&#xD;mediumpurple&#xD;mediumseagreen&#xD;mediumslateblue&#xD;mediumspringgreen&#xD;mediumturquoise&#xD;mediumvioletred&#xD;midnightblue&#xD;mintcream&#xD;mistyrose&#xD;moccasin&#xD;navajowhite&#xD;navy&#xD;oldlace&#xD;olive&#xD;olivedrab&#xD;orange&#xD;orangered&#xD;orchid&#xD;palegoldenrod&#xD;palegreen&#xD;paleturquoise&#xD;palevioletred&#xD;papayawhip&#xD;peachpuff&#xD;peru&#xD;pink&#xD;plum&#xD;powderblue&#xD;purple&#xD;red&#xD;rosybrown&#xD;royalblue&#xD;saddlebrown&#xD;salmon&#xD;sandybrown&#xD;seagreen&#xD;seashell&#xD;sienna&#xD;silver&#xD;skyblue&#xD;slateblue&#xD;slategray&#xD;slategrey&#xD;snow&#xD;springgreen&#xD;steelblue&#xD;tan&#xD;teal&#xD;thistle&#xD;tomato&#xD;turquoise&#xD;violet&#xD;wheat&#xD;white&#xD;whitesmoke&#xD;yellow&#xD;yellowgreen&#xD;Continuous color names&#xD;#&#xD;aggrnyl&#xD;agsunset&#xD;blackbody&#xD;bluered&#xD;blues&#xD;blugrn&#xD;bluyl&#xD;brwnyl&#xD;bugn&#xD;bupu&#xD;burg&#xD;burgyl&#xD;cividis&#xD;darkmint&#xD;electric&#xD;emrld&#xD;gnbu&#xD;greens&#xD;greys&#xD;hot&#xD;inferno&#xD;jet&#xD;magenta&#xD;magma&#xD;mint&#xD;orrd&#xD;oranges&#xD;oryel&#xD;peach&#xD;pinkyl&#xD;plasma&#xD;plotly3&#xD;pubu&#xD;pubugn&#xD;purd&#xD;purp&#xD;purples&#xD;purpor&#xD;rainbow&#xD;rdbu&#xD;rdpu&#xD;redor&#xD;reds&#xD;sunset&#xD;sunsetdark&#xD;teal&#xD;tealgrn&#xD;turbo&#xD;viridis&#xD;ylgn&#xD;ylgnbu&#xD;ylorbr&#xD;ylorrd&#xD;algae&#xD;amp&#xD;deep&#xD;dense&#xD;gray&#xD;haline&#xD;ice&#xD;matter&#xD;solar&#xD;speed&#xD;tempo&#xD;thermal&#xD;turbid&#xD;armyrose&#xD;brbg&#xD;earth&#xD;fall&#xD;geyser&#xD;prgn&#xD;piyg&#xD;picnic&#xD;portland&#xD;puor&#xD;rdgy&#xD;rdylbu&#xD;rdylgn&#xD;spectral&#xD;tealrose&#xD;temps&#xD;tropic&#xD;balance&#xD;curl&#xD;delta&#xD;oxy&#xD;edge&#xD;hsv&#xD;icefire&#xD;phase&#xD;twilight&#xD;mrybm&#xD;mygbm&#xD;Code&#xD;#&#xD;plotlycolors.</description>
    </item>
    <item>
      <title>Plotly: Drawing a plane perpendicular to a given line</title>
      <link>http://localhost:1313/posts/blog/plane/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/blog/plane/</guid>
      <description>When I am working on my binder design task, I need to select suitable hotspot residues that can lead to design better binders. In addition to hydrophobic amino acids, I also want to focus on the amino acids whose positions are close to the outside edge, and far away from the center of the protein. Therefore, I expect a plane that can approximately cut the protein layer by layer with my expected distance to the outside edge.</description>
    </item>
    <item>
      <title>processing its output of blastp</title>
      <link>http://localhost:1313/posts/proteomics/outofblast/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/proteomics/outofblast/</guid>
      <description>&#xD;E-value&#xD;#&#xD;</description>
    </item>
    <item>
      <title>Protein structure measurement</title>
      <link>http://localhost:1313/posts/blog/assessment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/blog/assessment/</guid>
      <description>pLDDT&#xD;#&#xD;&amp;ldquo;predicted Local Distance Difference Test&amp;rdquo; is a per-residue measure of local confidence. It is scaled from 0 to 100, with higher scores indicating higher confidence and usually a more accurate prediction. ref&#xA;PAE&#xD;#&#xD;Predicted Aligned Error (PAE) is a measure of how confident AlphaFold2 is in the relative position of two residues within the predicted structure. PAE is defined as the expected positional error at residue X, measured in Ångströms (Å), if the predicted and actual structures were aligned on residue Y.</description>
    </item>
    <item>
      <title>read data</title>
      <link>http://localhost:1313/posts/proteomics/readdata/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/proteomics/readdata/</guid>
      <description>&#xD;read id and seq from .fasta&#xD;#&#xD;from Bio import SeqIO with open(&amp;#39;fa.fasta&amp;#39;) as fasta_file: identifiers, seq = [], [] for seq_record in SeqIO.parse(fasta_file, &amp;#39;fasta&amp;#39;): identifiers.append(seq_record.id) seq.append(&amp;#34;&amp;#34;.join(seq_record.seq)) fa_df = pd.DataFrame() fa_df[&amp;#34;seq&amp;#34;] = seq fa_df[&amp;#34;id&amp;#34;] = identifiers pandas read&#xD;#&#xD;pd.read_csv(&amp;#39;result.csv&amp;#39;, header=None, index_col=0) # index_col=False </description>
    </item>
    <item>
      <title>remove DNA/RNA and O from pdb format</title>
      <link>http://localhost:1313/posts/proteomics/removedrna/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/proteomics/removedrna/</guid>
      <description>from Bio import PDB class rm_dna_rna_O(PDB.Select): def accept_residue(self, res): if (len(res.get_resname()) &amp;lt;3) or (res.id[0] != &amp;#34; &amp;#34;): return False else: return True if __name__==&amp;#34;__main__&amp;#34;: for pdbfile_path in glob.glob(&amp;#34;/path/PDBDB/*.pdb&amp;#34;): print(pdbfile_path, end=&amp;#34; &amp;#34;) name = pdbfile_path.split(&amp;#34;/&amp;#34;)[-1] pdb = PDB.PDBParser().get_structure(name, pdbfile_path) pdb_io = PDB.PDBIO() pdb_io.set_structure(pdb) pdb_io.save(&amp;#34;/path/PDBDB_no_drna/&amp;#34;+name, rm_dna_rna_O()) print(&amp;#39;-- Done&amp;#39;) </description>
    </item>
    <item>
      <title>remove HETATOM from pdb format</title>
      <link>http://localhost:1313/posts/proteomics/removehetatom/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/proteomics/removehetatom/</guid>
      <description>from Bio import PDB pdb = PDB.PDBParser().get_structure(&amp;#34;2gq1&amp;#34;, &amp;#34;FBP/2gq1.pdb&amp;#34;) class ResSelect(PDB.Select): def accept_residue(self, res): if res.id[0] != &amp;#34; &amp;#34;: #&amp;gt;= start_res and res.id[1] &amp;lt;= end_res and res.parent.id == chain_id: return False else: return True pdb_io = PDB.PDBIO() pdb_io.set_structure(pdb) pdb_io.save(&amp;#34;FBP/2gq1_no_HETATOM.pdb&amp;#34;, ResSelect()) </description>
    </item>
    <item>
      <title>SeqIO.parse()</title>
      <link>http://localhost:1313/posts/proteomics/seqio/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/proteomics/seqio/</guid>
      <description>from Bio import SeqIO with open(&amp;#34;fa.fasta&amp;#34;) as fa: for record in SeqIO.parse(fa, &amp;#34;fasta&amp;#34;): ID = record.id seq = record.seq description = recrod.description </description>
    </item>
    <item>
      <title>Sequence Alignment</title>
      <link>http://localhost:1313/posts/proteomics/seqalign/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/proteomics/seqalign/</guid>
      <description></description>
    </item>
    <item>
      <title>sequence alignment via BLASTp with using makeblastdb for custom database</title>
      <link>http://localhost:1313/posts/proteomics/blast/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/proteomics/blast/</guid>
      <description>cd root/OMGstudy/&#xD;tree&#xD;.&#xD;├── query.fasta&#xD;├── OMGDB_blast&#xD;├── OMGDB_fasta&#xD;└── OMGDB.fasta&#xD;makeblastdb -in ./OMGDB_fasta/OMGDB.fasta -input_type fasta -dbtype prot -out ./OMGDB_blast/OMGDB.blast&#xD;tree&#xD;.&#xD;├── query.fasta&#xD;├── OMGDB_blast&#xD;│ ├── OMGDB.blast.00.phr&#xD;│ ├── OMGDB.blast.00.pin&#xD;│ ├── OMGDB.blast.00.psq&#xD;│ ├── OMGDB.blast.01.phr&#xD;│ ├── OMGDB.blast.01.pin&#xD;... ...&#xD;│ ├── OMGDB.blast.30.psq&#xD;│ ├── OMGDB.blast.31.phr&#xD;│ ├── OMGDB.blast.31.pin&#xD;... ...&#xD;│ ├── OMGDB.blast.43.phr&#xD;│ ├── OMGDB.blast.43.pin&#xD;│ ├── OMGDB.blast.43.psq&#xD;│ ├── OMGDB.blast.pal&#xD;│ ├── OMGDB.blast.pdb&#xD;│ ├── OMGDB.</description>
    </item>
    <item>
      <title>use unipressed.UniprotkbClient analysis UniProt(Swiss-Prot) DB</title>
      <link>http://localhost:1313/posts/proteomics/uniprotana/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/proteomics/uniprotana/</guid>
      <description>We can reveal these information.&#xA;To minimize duplications between the UniProt Swiss-Prot database and the PDB database, I focused on downloading the structures of 513,805 entries from UniProt (Swiss-Prot) that are only available in the Alphafold Protein Structure Database. Therefore, I only need to download 4,274 entries&amp;rsquo; structures, because the remaining 509,531 entries&amp;rsquo; structures can be directly extracted from (Fig.2).&#xD;{&amp;#39;AFDB&amp;#39;: &amp;#39;hasAFDB&amp;#39;,&#xD;&amp;#39;PDB&amp;#39;: &amp;#39;no&amp;#39;,&#xD;&amp;#39;annotationScore&amp;#39;: 1.0,&#xD;&amp;#39;comments&amp;#39;: nan,&#xD;&amp;#39;entryAudit&amp;#39;: &amp;#34;{&amp;#39;firstPublicDate&amp;#39;: &amp;#39;1988-08-01&amp;#39;, &amp;#39;lastAnnotationUpdateDate&amp;#39;: &amp;#34;&#xD;&amp;#34;&amp;#39;2022-05-25&amp;#39;, &amp;#39;lastSequenceUpdateDate&amp;#39;: &amp;#39;1988-08-01&amp;#39;, &amp;#34;&#xD;&amp;#34;&amp;#39;entryVersion&amp;#39;: 36, &amp;#39;sequenceVersion&amp;#39;: 1}&amp;#34;,&#xD;&amp;#39;entryType&amp;#39;: &amp;#39;UniProtKB reviewed (Swiss-Prot)&amp;#39;,&#xD;&amp;#39;extraAttributes&amp;#39;: &amp;#34;{&amp;#39;countByFeatureType&amp;#39;: {&amp;#39;Chain&amp;#39;: 1}, &amp;#39;uniParcId&amp;#39;: &amp;#34;&#xD;&amp;#34;&amp;#39;UPI000013C2E9&amp;#39;}&amp;#34;,&#xD;&amp;#39;features&amp;#39;: &amp;#34;[{&amp;#39;type&amp;#39;: &amp;#39;Chain&amp;#39;, &amp;#39;location&amp;#39;: {&amp;#39;start&amp;#39;: {&amp;#39;value&amp;#39;: 1, &amp;#34;&#xD;&amp;#34;&amp;#39;modifier&amp;#39;: &amp;#39;EXACT&amp;#39;}, &amp;#39;end&amp;#39;: {&amp;#39;value&amp;#39;: 79, &amp;#39;modifier&amp;#39;: &amp;#34;&#xD;&amp;#34;&amp;#39;EXACT&amp;#39;}}, &amp;#39;description&amp;#39;: &amp;#39;Putative uncharacterized protein Z&amp;#39;, &amp;#34;&#xD;&amp;#34;&amp;#39;featureId&amp;#39;: &amp;#39;PRO_0000066556&amp;#39;}]&amp;#34;,&#xD;&amp;#39;geneLocations&amp;#39;: nan,&#xD;&amp;#39;genes&amp;#39;: nan,&#xD;&amp;#39;index&amp;#39;: 860,&#xD;&amp;#39;keywords&amp;#39;: &amp;#34;[{&amp;#39;id&amp;#39;: &amp;#39;KW-1185&amp;#39;, &amp;#39;category&amp;#39;: &amp;#39;Technical term&amp;#39;, &amp;#39;name&amp;#39;: &amp;#34;&#xD;&amp;#34;&amp;#39;Reference proteome&amp;#39;}]&amp;#34;,&#xD;&amp;#39;organism&amp;#39;: &amp;#34;{&amp;#39;scientificName&amp;#39;: &amp;#39;Ovis aries&amp;#39;, &amp;#39;commonName&amp;#39;: &amp;#39;Sheep&amp;#39;, &amp;#34;&#xD;&amp;#34;&amp;#39;taxonId&amp;#39;: 9940, &amp;#39;lineage&amp;#39;: [&amp;#39;Eukaryota&amp;#39;, &amp;#39;Metazoa&amp;#39;, &amp;#39;Chordata&amp;#39;, &amp;#34;&#xD;&amp;#34;&amp;#39;Craniata&amp;#39;, &amp;#39;Vertebrata&amp;#39;, &amp;#39;Euteleostomi&amp;#39;, &amp;#39;Mammalia&amp;#39;, &amp;#34;&#xD;&amp;#34;&amp;#39;Eutheria&amp;#39;, &amp;#39;Laurasiatheria&amp;#39;, &amp;#39;Artiodactyla&amp;#39;, &amp;#39;Ruminantia&amp;#39;, &amp;#34;&#xD;&amp;#34;&amp;#39;Pecora&amp;#39;, &amp;#39;Bovidae&amp;#39;, &amp;#39;Caprinae&amp;#39;, &amp;#39;Ovis&amp;#39;]}&amp;#34;,&#xD;&amp;#39;organismHosts&amp;#39;: nan,&#xD;&amp;#39;primaryAccession&amp;#39;: &amp;#39;P08105&amp;#39;,&#xD;&amp;#39;proteinDescription&amp;#39;: &amp;#34;{&amp;#39;recommendedName&amp;#39;: {&amp;#39;fullName&amp;#39;: {&amp;#39;value&amp;#39;: &amp;#39;Putative &amp;#34;&#xD;&amp;#34;uncharacterized protein Z&amp;#39;}}}&amp;#34;,&#xD;&amp;#39;proteinExistence&amp;#39;: &amp;#39;4: Predicted&amp;#39;,&#xD;&amp;#39;references&amp;#39;: &amp;#34;[{&amp;#39;referenceNumber&amp;#39;: 1, &amp;#39;citation&amp;#39;: {&amp;#39;id&amp;#39;: &amp;#39;6193483&amp;#39;, &amp;#34;&#xD;&amp;#34;&amp;#39;citationType&amp;#39;: &amp;#39;journal article&amp;#39;, &amp;#39;authors&amp;#39;: [&amp;#39;Powell B.</description>
    </item>
    <item>
      <title>Website via Hugo Book and deployed by Github Action</title>
      <link>http://localhost:1313/posts/blog/hugobookgithubaction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/blog/hugobookgithubaction/</guid>
      <description>In Windows10, build personal website via Hugo-book and Github Actions&#xD;#&#xD;This blog is about how to use Hugo to create the local website, and then deploy it on GitHub via Github Action. Everything is step by step.&#xA;Prerequisites&#xD;#&#xD;Git Windows 10 VScode Github account Install Hugo&#xD;#&#xD;In Windows10, right click Windows Powershell and click run as administrator. Refer to How to install chocolatey in Windows to install chocolatey.</description>
    </item>
  </channel>
</rss>
