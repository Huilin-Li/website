<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>omics on Huilin Li</title>
    <link>http://localhost:1313/posts/omics/</link>
    <description>Recent content in omics on Huilin Li</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="http://localhost:1313/posts/omics/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>commonly used Shell script and Command line, when working on large dataset in HPC</title>
      <link>http://localhost:1313/posts/omics/command/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/omics/command/</guid>
      <description>ls -l | wc -l wget -i links.txt </description>
    </item>
    <item>
      <title>databases: PDB, Swiss-Prot</title>
      <link>http://localhost:1313/posts/omics/database/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/omics/database/</guid>
      <description>PDB database&#xD;#&#xD;download&#xD;#&#xD;https://files.rcsb.org/pub/pdb/data/structures/all/pdb/ save this website PDB - FTP Archive over HTTP.html extract pdbXXXX.ent.gz list from bs4 import BeautifulSoup # how many ent.gz file with open(&amp;#39;PDB - FTP Archive over HTTP.html&amp;#39;, &amp;#39;r&amp;#39;) as file: html_content = file.read() soup = BeautifulSoup(html_content, &amp;#39;lxml&amp;#39;) text = soup.get_text(&amp;#39;\n&amp;#39;, &amp;#39;\n\n&amp;#39;) lines = text.split(&amp;#39;\n&amp;#39;) PDB_id_list = [] for line in lines: if &amp;#39;ent.gz&amp;#39; in line: PDB_id_list.append(line.split(&amp;#34;.&amp;#34;)[0].split(&amp;#34;pdb&amp;#34;)[1]) # PDB_id_list[:5] # [&amp;#39;100d&amp;#39;, &amp;#39;101d&amp;#39;, &amp;#39;101m&amp;#39;, &amp;#39;102d&amp;#39;, &amp;#39;102l&amp;#39;] parallel downloads # split into 44 entry_i.</description>
    </item>
    <item>
      <title>fasta similarity</title>
      <link>http://localhost:1313/posts/omics/fasimilarity/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/omics/fasimilarity/</guid>
      <description>&#xD;import parasail&#xD;#&#xD;result = parasail.sw_trace_scan_16(&amp;#34;asdf&amp;#34;, &amp;#34;asdf&amp;#34;, 11, 1, parasail.blosum62) </description>
    </item>
    <item>
      <title>files list</title>
      <link>http://localhost:1313/posts/omics/files/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/omics/files/</guid>
      <description>&#xD;list files in a folder&#xD;#&#xD;import glob files = glob.glob(&amp;#39;CSV/*.csv&amp;#39;) # [&amp;#39;CSV\\x_109.csv&amp;#39;, &amp;#39;CSV\\x_116.csv&amp;#39;, &amp;#39;CSV\\x_121.csv&amp;#39;, ... ] #&#xD;</description>
    </item>
    <item>
      <title>pdb 2 fasta</title>
      <link>http://localhost:1313/posts/omics/pdb2fasta/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/omics/pdb2fasta/</guid>
      <description>from Bio import SeqIO def pdb2fasta(pdb_file, fasta_file, HEADER=None): with open(pdb_file, &amp;#39;r&amp;#39;) as pdb_file: for record in SeqIO.parse(pdb_file, &amp;#39;pdb-atom&amp;#39;): if &amp;#39;?&amp;#39; in record.id: header = HEADER else: header = record.id with open(fasta_file, &amp;#39;w&amp;#39;) as fasta_file: fasta_file.write(&amp;#39;&amp;gt;&amp;#39; + header+&amp;#39;\n&amp;#39;) fasta_file.write(str(record.seq)) return record.seq </description>
    </item>
    <item>
      <title>read data</title>
      <link>http://localhost:1313/posts/omics/readdata/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/omics/readdata/</guid>
      <description>&#xD;read id and seq from .fasta&#xD;#&#xD;from Bio import SeqIO with open(&amp;#39;fa.fasta&amp;#39;) as fasta_file: identifiers, seq = [], [] for seq_record in SeqIO.parse(fasta_file, &amp;#39;fasta&amp;#39;): identifiers.append(seq_record.id) seq.append(&amp;#34;&amp;#34;.join(seq_record.seq)) fa_df = pd.DataFrame() fa_df[&amp;#34;seq&amp;#34;] = seq fa_df[&amp;#34;id&amp;#34;] = identifiers pandas read&#xD;#&#xD;pd.read_csv(&amp;#39;result.csv&amp;#39;, header=None, index_col=0) # index_col=False </description>
    </item>
    <item>
      <title>remove HETATOM from pdb format</title>
      <link>http://localhost:1313/posts/omics/removehetatom/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/omics/removehetatom/</guid>
      <description>from Bio import PDB pdb = PDB.PDBParser().get_structure(&amp;#34;2gq1&amp;#34;, &amp;#34;FBP/2gq1.pdb&amp;#34;) class ResSelect(PDB.Select): def accept_residue(self, res): if res.id[0] != &amp;#34; &amp;#34;: #&amp;gt;= start_res and res.id[1] &amp;lt;= end_res and res.parent.id == chain_id: return False else: return True pdb_io = PDB.PDBIO() pdb_io.set_structure(pdb) pdb_io.save(&amp;#34;FBP/2gq1_no_HETATOM.pdb&amp;#34;, ResSelect()) </description>
    </item>
  </channel>
</rss>
